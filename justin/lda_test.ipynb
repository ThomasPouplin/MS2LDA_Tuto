{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beer3 Positive Results\n",
    "=============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LDA\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lda_for_fragments import run_lda\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_topics = 50\n",
    "n_samples = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features.**\n",
    "\n",
    "For each document (i.e. parent peak), we have the following bag-of-words of features:\n",
    "1. The discretised m/z value of its fragment peaks. For the value, we use the the logged intensity of the fragment peak, scaled from 0..100.\n",
    "2. The discretised m/z value of neutral losses. For the value, we use the log intensity of the neutral loss peak, scaled from 0..100.\n",
    "3. The discretised m/z differences between each pair of fragment peaks. For the value, we use the count of occurences of such m/z differences (e.g. 1, 2, 3), scaled from 0..100.\n",
    "\n",
    "A lot of heuristics (thresholding, etc). were used when extracting these features from the mzXML files. See extractFeatures.R for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discretisation step we use to prerocess the input before passing it to the model seems quite dodgy now. We see in the histogram below the tall bars at bin=10, 20 and 30. These come from (3) above. The rest of the histogram bins come from (1) and (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0ae6b39310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin=0 count=0.0\n",
      "bin=1 count=0.0\n",
      "bin=2 count=0.0\n",
      "bin=3 count=0.0\n",
      "bin=4 count=0.0\n",
      "bin=5 count=0.0\n",
      "bin=6 count=0.0\n",
      "bin=7 count=0.0\n",
      "bin=8 count=0.0\n",
      "bin=9 count=0.0\n",
      "bin=10 count=25649.0\n",
      "bin=11 count=0.0\n",
      "bin=12 count=0.0\n",
      "bin=13 count=0.0\n",
      "bin=14 count=0.0\n",
      "bin=15 count=0.0\n",
      "bin=16 count=0.0\n",
      "bin=17 count=0.0\n",
      "bin=18 count=0.0\n",
      "bin=19 count=0.0\n",
      "bin=20 count=2771.0\n",
      "bin=21 count=0.0\n",
      "bin=22 count=0.0\n",
      "bin=23 count=0.0\n",
      "bin=24 count=0.0\n",
      "bin=25 count=0.0\n",
      "bin=26 count=0.0\n",
      "bin=27 count=0.0\n",
      "bin=28 count=0.0\n",
      "bin=29 count=0.0\n",
      "bin=30 count=554.0\n",
      "bin=31 count=0.0\n",
      "bin=32 count=0.0\n",
      "bin=33 count=0.0\n",
      "bin=34 count=0.0\n",
      "bin=35 count=0.0\n",
      "bin=36 count=0.0\n",
      "bin=37 count=0.0\n",
      "bin=38 count=0.0\n",
      "bin=39 count=0.0\n",
      "bin=40 count=135.0\n",
      "bin=41 count=0.0\n",
      "bin=42 count=109.0\n",
      "bin=43 count=554.0\n",
      "bin=44 count=829.0\n",
      "bin=45 count=882.0\n",
      "bin=46 count=804.0\n",
      "bin=47 count=821.0\n",
      "bin=48 count=802.0\n",
      "bin=49 count=753.0\n",
      "bin=50 count=656.0\n",
      "bin=51 count=555.0\n",
      "bin=52 count=474.0\n",
      "bin=53 count=455.0\n",
      "bin=54 count=461.0\n",
      "bin=55 count=412.0\n",
      "bin=56 count=334.0\n",
      "bin=57 count=310.0\n",
      "bin=58 count=286.0\n",
      "bin=59 count=241.0\n",
      "bin=60 count=243.0\n",
      "bin=61 count=173.0\n",
      "bin=62 count=156.0\n",
      "bin=63 count=130.0\n",
      "bin=64 count=101.0\n",
      "bin=65 count=76.0\n",
      "bin=66 count=66.0\n",
      "bin=67 count=67.0\n",
      "bin=68 count=51.0\n",
      "bin=69 count=41.0\n",
      "bin=70 count=56.0\n",
      "bin=71 count=38.0\n",
      "bin=72 count=36.0\n",
      "bin=73 count=16.0\n",
      "bin=74 count=11.0\n",
      "bin=75 count=25.0\n",
      "bin=76 count=15.0\n",
      "bin=77 count=10.0\n",
      "bin=78 count=7.0\n",
      "bin=79 count=10.0\n",
      "bin=80 count=9.0\n",
      "bin=81 count=2.0\n",
      "bin=82 count=3.0\n",
      "bin=83 count=3.0\n",
      "bin=84 count=0.0\n",
      "bin=85 count=1.0\n",
      "bin=86 count=3.0\n",
      "bin=87 count=3.0\n",
      "bin=88 count=0.0\n",
      "bin=89 count=2.0\n",
      "bin=90 count=2.0\n",
      "bin=91 count=0.0\n",
      "bin=92 count=2.0\n",
      "bin=93 count=0.0\n",
      "bin=94 count=0.0\n",
      "bin=95 count=1.0\n",
      "bin=96 count=0.0\n",
      "bin=97 count=0.0\n",
      "bin=98 count=0.0\n",
      "Data shape (856, 3758)\n",
      "Fitting model...\n"
     ]
    }
   ],
   "source": [
    "data, model, topicdf, docdf = run_lda('beer3_pos', \n",
    "                         'input/Beer_3_T10_POS_fragments.csv', \n",
    "                         'input/Beer_3_T10_POS_losses.csv', \n",
    "                         'input/Beer_3_T10_POS_mzdiffs.csv', \n",
    "                         n_topics, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA results can be found in the three files generated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. PCA\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use PCA to project the topics to lower-dimensional space for visualisation purposes. First ensure the variables are scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# df = docdf # topics x documents matrix\n",
    "df = topicdf.transpose() # topics x words matrix\n",
    "print df.shape\n",
    "\n",
    "# normalise and scale the variables\n",
    "scaled_mat = preprocessing.scale(df, axis=0)\n",
    "# print scaled_mat.mean(axis=0)\n",
    "# print scaled_mat.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(scaled_mat)\n",
    "X_r = pca.transform(scaled_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the explained variances by the first two principal components are too low ..??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_r.shape\n",
    "print('explained variance by the first two principal components: %s' % str(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X_r[:, 0], X_r[:, 1])\n",
    "plt.xlabel('1st princomp')\n",
    "plt.ylabel('2nd princomp')\n",
    "plt.title('Projected topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Network\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to put the topics on a network too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = topicdf.transpose()\n",
    "print df.shape # df is the topic x terms matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create adjacency matrix A\n",
    "\n",
    "# first compute euclidean distance between the topics\n",
    "from scipy.spatial.distance import cdist\n",
    "A = cdist(scaled_mat, scaled_mat, 'euclidean')\n",
    "\n",
    "# crudely convert to similarities\n",
    "maxval = A.max()\n",
    "A = 1-(A/maxval)\n",
    "plt.hist(A)\n",
    "\n",
    "# set a threshold of 0.3 for the similarity values for the network graph\n",
    "for i in xrange(A.shape[0]):\n",
    "    for j in xrange(A.shape[1]):\n",
    "        if A[i, j] < 0.40:\n",
    "            A[i, j] = 0\n",
    "\n",
    "plt.matshow(A)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "dt = [('len', float)]\n",
    "A = A.view(dt)\n",
    "G = nx.from_numpy_matrix(A)\n",
    "pos = nx.spring_layout(G, k=0.3, iterations=20)\n",
    "nx.draw(G,pos,font_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard to conclude antyhing .... It seems like there are some 'core' topics that the rest are connected to (in the high-dimensional Euclidean space). However, take note the network graph above can be misleading due to the thresholding values used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Topics\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the document-topic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = docdf.transpose()\n",
    "print df.shape\n",
    "plt.pcolor(df, norm=None, cmap='Blues')\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Topics')\n",
    "plt.ylabel('Parent peaks')\n",
    "plt.title('Documents-topics distributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every topic, check the words inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_docs = 10\n",
    "n_fragments = 20\n",
    "\n",
    "topic_fragments = model.topic_word_\n",
    "headers = list(docdf.columns.values)\n",
    "\n",
    "for i, topic_dist in enumerate(topic_fragments):\n",
    "    \n",
    "    print \"Topic \" + str(i)\n",
    "    print \"==========\"\n",
    "    print\n",
    "    \n",
    "    column_values = np.array(docdf.columns.values)    \n",
    "    doc_dist = docdf.iloc[[i]].as_matrix().flatten()\n",
    "    idx = np.argsort(doc_dist)[::-1] # argsort in descending order\n",
    "    topic_d = np.array(column_values)[idx]\n",
    "    topic_p = np.array(doc_dist)[idx]\n",
    "    top_n_docs = topic_d[1:n_docs]\n",
    "    top_n_docs_p = topic_p[1:n_docs]\n",
    "    \n",
    "    print \"Parent peaks\"\n",
    "    print \"\\n\".join(' - %s\\t%.3f' % t for t in zip(top_n_docs, top_n_docs_p))\n",
    "\n",
    "    column_values = np.array(data.columns.values)\n",
    "    idx = np.argsort(topic_dist)[::-1] # argsort in descending order\n",
    "    topic_w = np.array(column_values)[idx]\n",
    "    topic_p = np.array(topic_dist)[idx]    \n",
    "    fragments = []\n",
    "    fragments_p = []\n",
    "    others = []\n",
    "    others_p = []\n",
    "    for w, p in zip(topic_w, topic_p):\n",
    "        if len(fragments) > n_fragments:\n",
    "            break\n",
    "        if w.startswith('fragment'):\n",
    "            fragments.append(w)\n",
    "            fragments_p.append(p)\n",
    "        else:\n",
    "            others.append(w)\n",
    "            others_p.append(p)\n",
    "\n",
    "    print \"Fragments\"\n",
    "    print \"\\n\".join(' - %s\\t%.3f' % t for t in zip(fragments, fragments_p))\n",
    "\n",
    "    print \"Others\"\n",
    "    print \"\\n\".join(' - %-15s\\t%.3f' % t for t in zip(others, others_p))\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "make a plot (plus the intensity) from the report above ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. No. of Topics\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the held-out perplexity on the testing set and plot as the no. of topics is increased .."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
