{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beer3 Positive Results\n",
    "============"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LDA\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "basedir = '../'\n",
    "sys.path.append(basedir)\n",
    "\n",
    "from lda_for_fragments import Ms2Lda\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_topics = 100\n",
    "n_samples = 100\n",
    "\n",
    "fragment_filename = 'input/Beer_3_T10_POS_fragments.csv'\n",
    "neutral_loss_filename = 'input/Beer_3_T10_POS_losses.csv'\n",
    "mzdiff_filename = None\n",
    "\n",
    "ms1_filename = 'input/Beer_3_T10_POS_ms1.csv'\n",
    "ms2_filename = 'input/Beer_3_T10_POS_ms2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes at most 7 arguments (8 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0c4a756f3ca8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m ms2lda = Ms2Lda(fragment_filename, neutral_loss_filename, mzdiff_filename, \n\u001b[1;32m----> 2\u001b[1;33m                 ms1_filename, ms2_filename, n_topics, n_samples)\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mms2lda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_lda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() takes at most 7 arguments (8 given)"
     ]
    }
   ],
   "source": [
    "ms2lda = Ms2Lda(fragment_filename, neutral_loss_filename, mzdiff_filename, \n",
    "                ms1_filename, ms2_filename)\n",
    "df = ms2lda.preprocess()\n",
    "ms2lda.run_lda(df, n_topics, n_samples, n_burn, n_thin, \n",
    "               alpha, beta, use_own_model=True, use_inline=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ms2lda.write_results('beer3_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_fragments = ms2lda.model.topic_word_\n",
    "n_top_frags = 20\n",
    "for i,topic_dist in enumerate(topic_fragments):\n",
    "    topic_f = np.array(ms2lda.data.columns.values)[np.argsort(topic_dist)][:-n_top_frags:-1]\n",
    "    out_string = 'Topic {}: {}'.format(i, ', '.join(topic_f.astype('str')))\n",
    "    print(out_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(ms2lda.model.loglikelihoods_)\n",
    "plt.plot(ms2lda.model.loglikelihoods_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. PCA\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use PCA to project the vector of topics for each parent peak to lower-dimensional space for visualisation purposes. First ensure the variables are scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = ms2lda.docdf.transpose() # topics x documents matrix\n",
    "# df = fragments_topicdf.transpose() # topics x words matrix\n",
    "print df.shape\n",
    "\n",
    "# normalise and scale the variables\n",
    "scaled_mat = preprocessing.scale(df, axis=0)\n",
    "# print scaled_mat.mean(axis=0)\n",
    "# print scaled_mat.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(scaled_mat)\n",
    "X_r = pca.transform(scaled_mat)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(X_r[:, 0], bins=30)\n",
    "plt.title('First transformed variable')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(X_r[:, 1], bins=30)\n",
    "plt.title('Second transformed variable')\n",
    "plt.show()\n",
    "\n",
    "print np.argmax(np.abs(pca.components_[0, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the explained variances by the first few principal components are too low ..??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_r.shape\n",
    "print np.sum(pca.explained_variance_ratio_)\n",
    "print('explained variance by the principal components: %s' % str(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X_r[:, 0], X_r[:, 1])\n",
    "plt.xlabel('1st princomp')\n",
    "plt.ylabel('2nd princomp')\n",
    "plt.title('Projected parent peaks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Network\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to put the parent peaks on a network too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df = topicdf.transpose() # topic x terms matrix\n",
    "df = ms2lda.docdf.transpose() # documents x topic matrix\n",
    "print df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create adjacency matrix A\n",
    "\n",
    "# first compute euclidean distance between the topics\n",
    "from scipy.spatial.distance import cdist\n",
    "A = cdist(df, df, 'euclidean')\n",
    "print A.shape\n",
    "\n",
    "# crudely convert to similarities\n",
    "maxval = A.max()\n",
    "A = 1-(A/maxval)\n",
    "plt.figure()\n",
    "plt.hist(A)\n",
    "plt.title('Histogram of values in the adjacency matrix')\n",
    "plt.show()\n",
    "\n",
    "# set a threshold for the similarity values for the network graph\n",
    "for i in xrange(A.shape[0]):\n",
    "    for j in xrange(A.shape[1]):\n",
    "        if A[i, j] < 0.75:\n",
    "            A[i, j] = 0\n",
    "\n",
    "plt.figure()\n",
    "plt.matshow(A)\n",
    "plt.colorbar()\n",
    "plt.title('Adjacency matrix after thresholding', y=1.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = [('len', float)]\n",
    "A = A.view(dt)\n",
    "G = nx.from_numpy_matrix(A)\n",
    "pos = nx.spring_layout(G, k=0.01, iterations=20)\n",
    "nx.draw(G, pos, node_size=10, with_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see some connected components in the network graph. Below we print the largest top-20 components. \n",
    "\n",
    "Parent peaks in the same component are connected in the graph above, i.e. they form some sort of clusters, suggesting they share topics in common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "components = sorted(nx.connected_components(G), key = len, reverse=True)\n",
    "counter = 1\n",
    "for comp in components:\n",
    "    if counter > 20:\n",
    "        break\n",
    "    print \"Component \" + str(counter)\n",
    "    print \"==============\"\n",
    "    idx = np.array(comp)-1 # nodes are indexed from 1 .. N\n",
    "    ms1_rows = ms2lda.ms1.iloc[idx]\n",
    "    print ms1_rows[['peakID', 'mz', 'rt', 'intensity']].to_string(index=False, justify='left')\n",
    "    counter += 1\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Document-Topics Distribution\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the document-topic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = ms2lda.docdf.transpose()\n",
    "print df.shape\n",
    "plt.pcolor(df, norm=None, cmap='Blues')\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Topics')\n",
    "plt.ylabel('Parent peaks')\n",
    "plt.title('Documents-topics distributions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing useful here ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
