{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Notebook\n",
    "============"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Run LDA the first time</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "basedir = '../'\n",
    "sys.path.append(basedir)\n",
    "\n",
    "from lda_for_fragments import Ms2Lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (1588, 3171)\n"
     ]
    }
   ],
   "source": [
    "fragment_filename = basedir + 'input/final/Beer_3_full1_5_2E5_pos_fragments.csv'\n",
    "neutral_loss_filename = basedir + 'input/final/Beer_3_full1_5_2E5_pos_losses.csv'\n",
    "mzdiff_filename = None\n",
    "ms1_filename = basedir + 'input/final/Beer_3_full1_5_2E5_pos_ms1.csv'\n",
    "ms2_filename = basedir + 'input/final/Beer_3_full1_5_2E5_pos_ms2.csv'\n",
    "ms2lda = Ms2Lda.lcms_data_from_R(fragment_filename, neutral_loss_filename, mzdiff_filename, \n",
    "                             ms1_filename, ms2_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model...\n",
      "CGS LDA initialising\n",
      "...............................................................................................................................................................\n",
      "Using Numba for LDA sampling\n",
      "Preparing words\n",
      "Preparing Z matrix\n",
      "DONE\n",
      "Burn-in 1 \n",
      "Burn-in 2 \n",
      "Burn-in 3 \n",
      "Burn-in 4 \n",
      "Burn-in 5 \n",
      "Burn-in 6 \n",
      "Burn-in 7 \n",
      "Burn-in 8 \n",
      "Burn-in 9 \n",
      "Burn-in 10 \n",
      "Burn-in 11 \n",
      "Burn-in 12 \n",
      "Burn-in 13 \n",
      "Burn-in 14 \n",
      "Burn-in 15 \n",
      "Burn-in 16 \n",
      "Burn-in 17 \n",
      "Burn-in 18 \n",
      "Burn-in 19 \n",
      "Burn-in 20 \n",
      "Burn-in 21 \n",
      "Burn-in 22 \n",
      "Burn-in 23 \n",
      "Burn-in 24 \n",
      "Burn-in 25 \n",
      "Burn-in 26 \n",
      "Burn-in 27 \n",
      "Burn-in 28 \n",
      "Burn-in 29 \n",
      "Burn-in 30 \n",
      "Burn-in 31 \n",
      "Burn-in 32 \n",
      "Burn-in 33 \n",
      "Burn-in 34 \n",
      "Burn-in 35 \n",
      "Burn-in 36 \n",
      "Burn-in 37 \n",
      "Burn-in 38 \n",
      "Burn-in 39 \n",
      "Burn-in 40 \n",
      "Burn-in 41 \n",
      "Burn-in 42 \n",
      "Burn-in 43 \n",
      "Burn-in 44 \n",
      "Burn-in 45 \n",
      "Burn-in 46 \n",
      "Burn-in 47 \n",
      "Burn-in 48 \n",
      "Burn-in 49 \n",
      "Burn-in 50 \n",
      "Burn-in 51 \n",
      "Burn-in 52 \n",
      "Burn-in 53 \n",
      "Burn-in 54 \n",
      "Burn-in 55 \n",
      "Burn-in 56 \n",
      "Burn-in 57 \n",
      "Burn-in 58 \n",
      "Burn-in 59 \n",
      "Burn-in 60 \n",
      "Burn-in 61 \n",
      "Burn-in 62 \n",
      "Burn-in 63 \n",
      "Burn-in 64 \n",
      "Burn-in 65 \n",
      "Burn-in 66 \n",
      "Burn-in 67 \n",
      "Burn-in 68 \n",
      "Burn-in 69 \n",
      "Burn-in 70 \n",
      "Burn-in 71 \n",
      "Burn-in 72 \n",
      "Burn-in 73 \n",
      "Burn-in 74 \n",
      "Burn-in 75 \n",
      "Burn-in 76 \n",
      "Burn-in 77 \n",
      "Burn-in 78 \n",
      "Burn-in 79 \n",
      "Burn-in 80 \n",
      "Burn-in 81 \n",
      "Burn-in 82 \n",
      "Burn-in 83 \n",
      "Burn-in 84 \n",
      "Burn-in 85 \n",
      "Burn-in 86 \n",
      "Burn-in 87 \n",
      "Burn-in 88 \n",
      "Burn-in 89 \n",
      "Burn-in 90 \n",
      "Burn-in 91 \n",
      "Burn-in 92 \n",
      "Burn-in 93 \n",
      "Burn-in 94 \n",
      "Burn-in 95 \n",
      "Burn-in 96 \n",
      "Burn-in 97 \n",
      "Burn-in 98 \n",
      "Burn-in 99 \n",
      "Burn-in 100 \n",
      "Burn-in 101 \n",
      "Burn-in 102 \n",
      "Burn-in 103 \n",
      "Burn-in 104 \n",
      "Burn-in 105 \n",
      "Burn-in 106 \n",
      "Burn-in 107 \n",
      "Burn-in 108 \n",
      "Burn-in 109 \n",
      "Burn-in 110 \n",
      "Burn-in 111 \n",
      "Burn-in 112 \n",
      "Burn-in 113 \n",
      "Burn-in 114 \n",
      "Burn-in 115 \n",
      "Burn-in 116 \n",
      "Burn-in 117 \n",
      "Burn-in 118 \n",
      "Burn-in 119 \n",
      "Burn-in 120 \n",
      "Burn-in 121 \n",
      "Burn-in 122 \n",
      "Burn-in 123 \n",
      "Burn-in 124 \n",
      "Burn-in 125 \n",
      "Burn-in 126 \n",
      "Burn-in 127 \n",
      "Burn-in 128 \n",
      "Burn-in 129 \n",
      "Burn-in 130 \n",
      "Burn-in 131 \n",
      "Burn-in 132 \n",
      "Burn-in 133 \n",
      "Burn-in 134 \n",
      "Burn-in 135 \n",
      "Burn-in 136 \n",
      "Burn-in 137 \n",
      "Burn-in 138 \n",
      "Burn-in 139 \n",
      "Burn-in 140 \n",
      "Burn-in 141 \n",
      "Burn-in 142 \n",
      "Burn-in 143 \n",
      "Burn-in 144 \n",
      "Burn-in 145 \n",
      "Burn-in 146 \n",
      "Burn-in 147 \n",
      "Burn-in 148 \n",
      "Burn-in 149 \n",
      "Burn-in 150 \n",
      "Burn-in 151 \n",
      "Burn-in 152 \n",
      "Burn-in 153 \n",
      "Burn-in 154 \n",
      "Burn-in 155 \n",
      "Burn-in 156 \n",
      "Burn-in 157 \n",
      "Burn-in 158 \n",
      "Burn-in 159 \n",
      "Burn-in 160 \n",
      "Burn-in 161 \n",
      "Burn-in 162 \n",
      "Burn-in 163 \n",
      "Burn-in 164 \n",
      "Burn-in 165 \n",
      "Burn-in 166 \n",
      "Burn-in 167 \n",
      "Burn-in 168 \n",
      "Burn-in 169 \n",
      "Burn-in 170 \n",
      "Burn-in 171 \n",
      "Burn-in 172 \n",
      "Burn-in 173 \n",
      "Burn-in 174 \n",
      "Burn-in 175 \n",
      "Burn-in 176 \n",
      "Burn-in 177 \n",
      "Burn-in 178 \n",
      "Burn-in 179 \n",
      "Burn-in 180 \n",
      "Burn-in 181 \n",
      "Burn-in 182 \n",
      "Burn-in 183 \n",
      "Burn-in 184 \n",
      "Burn-in 185 \n",
      "Burn-in 186 \n",
      "Burn-in 187 \n",
      "Burn-in 188 \n",
      "Burn-in 189 \n",
      "Burn-in 190 \n",
      "Burn-in 191 \n",
      "Burn-in 192 \n",
      "Burn-in 193 \n",
      "Burn-in 194 \n",
      "Burn-in 195 \n",
      "Burn-in 196 \n",
      "Burn-in 197 \n",
      "Burn-in 198 \n",
      "Burn-in 199 \n",
      "Burn-in 200 \n",
      "Burn-in 201 \n",
      "Burn-in 202 \n",
      "Burn-in 203 \n",
      "Burn-in 204 \n",
      "Burn-in 205 \n",
      "Burn-in 206 \n",
      "Burn-in 207 \n",
      "Burn-in 208 \n",
      "Burn-in 209 \n",
      "Burn-in 210 \n",
      "Burn-in 211 \n",
      "Burn-in 212 \n",
      "Burn-in 213 \n",
      "Burn-in 214 \n",
      "Burn-in 215 \n",
      "Burn-in 216 \n",
      "Burn-in 217 \n",
      "Burn-in 218 \n",
      "Burn-in 219 \n",
      "Burn-in 220 \n",
      "Burn-in 221 \n",
      "Burn-in 222 \n",
      "Burn-in 223 \n",
      "Burn-in 224 \n",
      "Burn-in 225 \n",
      "Burn-in 226 \n",
      "Burn-in 227 \n",
      "Burn-in 228 \n",
      "Burn-in 229 \n",
      "Burn-in 230 \n",
      "Burn-in 231 \n",
      "Burn-in 232 \n",
      "Burn-in 233 \n",
      "Burn-in 234 \n",
      "Burn-in 235 \n",
      "Burn-in 236 \n",
      "Burn-in 237 \n",
      "Burn-in 238 \n",
      "Burn-in 239 \n",
      "Burn-in 240 \n",
      "Burn-in 241 \n",
      "Burn-in 242 \n",
      "Burn-in 243 \n",
      "Burn-in 244 \n",
      "Burn-in 245 \n",
      "Burn-in 246 \n",
      "Burn-in 247 \n",
      "Burn-in 248 \n",
      "Burn-in 249 \n",
      "Sample 250 \n",
      "Sample 251 \n",
      "Sample 252 \n",
      "Sample 253 \n",
      "Sample 254 \n",
      "Sample 255   Log joint likelihood = -2100292.816 \n",
      "Sample 256 \n",
      "Sample 257 \n",
      "Sample 258 \n",
      "Sample 259 \n",
      "Sample 260   Log joint likelihood = -2100106.592 \n",
      "Sample 261 \n",
      "Sample 262 \n",
      "Sample 263 \n",
      "Sample 264 \n",
      "Sample 265   Log joint likelihood = -2100059.955 \n",
      "Sample 266 \n",
      "Sample 267 \n",
      "Sample 268 \n",
      "Sample 269 \n",
      "Sample 270   Log joint likelihood = -2100116.306 \n",
      "Sample 271 \n",
      "Sample 272 \n",
      "Sample 273 \n",
      "Sample 274 \n",
      "Sample 275   Log joint likelihood = -2100176.687 \n",
      "Sample 276 \n",
      "Sample 277 \n",
      "Sample 278 \n",
      "Sample 279 \n",
      "Sample 280   Log joint likelihood = -2099975.402 \n",
      "Sample 281 \n",
      "Sample 282 \n",
      "Sample 283 \n",
      "Sample 284 \n",
      "Sample 285   Log joint likelihood = -2099103.824 \n",
      "Sample 286 \n",
      "Sample 287 \n",
      "Sample 288 \n",
      "Sample 289 \n",
      "Sample 290   Log joint likelihood = -2099242.688 \n",
      "Sample 291 \n",
      "Sample 292 \n",
      "Sample 293 \n",
      "Sample 294 \n",
      "Sample 295   Log joint likelihood = -2098554.790 \n",
      "Sample 296 \n",
      "Sample 297 \n",
      "Sample 298 \n",
      "Sample 299 \n",
      "Sample 300   Log joint likelihood = -2099129.274 \n",
      "Sample 301 \n",
      "Sample 302 \n",
      "Sample 303 \n",
      "Sample 304 \n",
      "Sample 305   Log joint likelihood = -2098813.586 \n",
      "Sample 306 \n",
      "Sample 307 \n",
      "Sample 308 \n",
      "Sample 309 \n",
      "Sample 310   Log joint likelihood = -2098799.258 \n",
      "Sample 311 \n",
      "Sample 312 \n",
      "Sample 313 \n",
      "Sample 314 \n",
      "Sample 315   Log joint likelihood = -2098602.363 \n",
      "Sample 316 \n",
      "Sample 317 \n",
      "Sample 318 \n",
      "Sample 319 \n",
      "Sample 320   Log joint likelihood = -2098734.351 \n",
      "Sample 321 \n",
      "Sample 322 \n",
      "Sample 323 \n",
      "Sample 324 \n",
      "Sample 325   Log joint likelihood = -2098376.327 \n",
      "Sample 326 \n",
      "Sample 327 \n",
      "Sample 328 \n",
      "Sample 329 \n",
      "Sample 330   Log joint likelihood = -2097845.041 \n",
      "Sample 331 \n",
      "Sample 332 \n",
      "Sample 333 \n",
      "Sample 334 \n",
      "Sample 335   Log joint likelihood = -2098289.989 \n",
      "Sample 336 \n",
      "Sample 337 \n",
      "Sample 338 \n",
      "Sample 339 \n",
      "Sample 340   Log joint likelihood = -2097530.589 \n",
      "Sample 341 \n",
      "Sample 342 \n",
      "Sample 343 \n",
      "Sample 344 \n",
      "Sample 345   Log joint likelihood = -2098114.458 \n",
      "Sample 346 \n",
      "Sample 347 \n",
      "Sample 348 \n",
      "Sample 349 \n",
      "Sample 350   Log joint likelihood = -2097872.114 \n",
      "Sample 351 \n",
      "Sample 352 \n",
      "Sample 353 \n",
      "Sample 354 \n",
      "Sample 355   Log joint likelihood = -2098156.126 \n",
      "Sample 356 \n",
      "Sample 357 \n",
      "Sample 358 \n",
      "Sample 359 \n",
      "Sample 360   Log joint likelihood = -2097685.196 \n",
      "Sample 361 \n",
      "Sample 362 \n",
      "Sample 363 \n",
      "Sample 364 \n",
      "Sample 365   Log joint likelihood = -2097555.948 \n",
      "Sample 366 \n",
      "Sample 367 \n",
      "Sample 368 \n",
      "Sample 369 \n",
      "Sample 370   Log joint likelihood = -2097560.348 \n",
      "Sample 371 \n",
      "Sample 372 \n",
      "Sample 373 \n",
      "Sample 374 \n",
      "Sample 375   Log joint likelihood = -2098244.203 \n",
      "Sample 376 \n",
      "Sample 377 \n",
      "Sample 378 \n",
      "Sample 379 \n",
      "Sample 380   Log joint likelihood = -2098281.753 \n",
      "Sample 381 \n",
      "Sample 382 \n",
      "Sample 383 \n",
      "Sample 384 \n",
      "Sample 385   Log joint likelihood = -2098650.774 \n",
      "Sample 386 \n",
      "Sample 387 \n",
      "Sample 388 \n",
      "Sample 389 \n",
      "Sample 390   Log joint likelihood = -2098036.292 \n",
      "Sample 391 \n",
      "Sample 392 \n",
      "Sample 393 \n",
      "Sample 394 \n",
      "Sample 395   Log joint likelihood = -2097314.131 \n",
      "Sample 396 \n",
      "Sample 397 \n",
      "Sample 398 \n",
      "Sample 399 \n",
      "Sample 400   Log joint likelihood = -2097603.714 \n",
      "Sample 401 \n",
      "Sample 402 \n",
      "Sample 403 \n",
      "Sample 404 \n",
      "Sample 405   Log joint likelihood = -2097200.520 \n",
      "Sample 406 \n",
      "Sample 407 \n",
      "Sample 408 \n",
      "Sample 409 \n",
      "Sample 410   Log joint likelihood = -2097514.756 \n",
      "Sample 411 \n",
      "Sample 412 \n",
      "Sample 413 \n",
      "Sample 414 \n",
      "Sample 415   Log joint likelihood = -2097265.847 \n",
      "Sample 416 \n",
      "Sample 417 \n",
      "Sample 418 \n",
      "Sample 419 \n",
      "Sample 420   Log joint likelihood = -2096772.322 \n",
      "Sample 421 \n",
      "Sample 422 \n",
      "Sample 423 \n",
      "Sample 424 \n",
      "Sample 425   Log joint likelihood = -2096846.471 \n",
      "Sample 426 \n",
      "Sample 427 \n",
      "Sample 428 \n",
      "Sample 429 \n",
      "Sample 430   Log joint likelihood = -2096843.650 \n",
      "Sample 431 \n",
      "Sample 432 \n",
      "Sample 433 \n",
      "Sample 434 \n",
      "Sample 435   Log joint likelihood = -2097111.076 \n",
      "Sample 436 \n",
      "Sample 437 \n",
      "Sample 438 \n",
      "Sample 439 \n",
      "Sample 440   Log joint likelihood = -2098105.746 \n",
      "Sample 441 \n",
      "Sample 442 \n",
      "Sample 443 \n",
      "Sample 444 \n",
      "Sample 445   Log joint likelihood = -2097438.783 \n",
      "Sample 446 \n",
      "Sample 447 \n",
      "Sample 448 \n",
      "Sample 449 \n",
      "Sample 450   Log joint likelihood = -2097253.601 \n",
      "Sample 451 \n",
      "Sample 452 \n",
      "Sample 453 \n",
      "Sample 454 \n",
      "Sample 455   Log joint likelihood = -2096784.858 \n",
      "Sample 456 \n",
      "Sample 457 \n",
      "Sample 458 \n",
      "Sample 459 \n",
      "Sample 460   Log joint likelihood = -2096990.258 \n",
      "Sample 461 \n",
      "Sample 462 \n",
      "Sample 463 \n",
      "Sample 464 \n",
      "Sample 465   Log joint likelihood = -2096935.712 \n",
      "Sample 466 \n",
      "Sample 467 \n",
      "Sample 468 \n",
      "Sample 469 \n",
      "Sample 470   Log joint likelihood = -2096241.138 \n",
      "Sample 471 \n",
      "Sample 472 \n",
      "Sample 473 \n",
      "Sample 474 \n",
      "Sample 475   Log joint likelihood = -2096891.731 \n",
      "Sample 476 \n",
      "Sample 477 \n",
      "Sample 478 \n",
      "Sample 479 \n",
      "Sample 480   Log joint likelihood = -2096526.992 \n",
      "Sample 481 \n",
      "Sample 482 \n",
      "Sample 483 \n",
      "Sample 484 \n",
      "Sample 485   Log joint likelihood = -2097390.929 \n",
      "Sample 486 \n",
      "Sample 487 \n",
      "Sample 488 \n",
      "Sample 489 \n",
      "Sample 490   Log joint likelihood = -2097390.034 \n",
      "Sample 491 \n",
      "Sample 492 \n",
      "Sample 493 \n",
      "Sample 494 \n",
      "Sample 495   Log joint likelihood = -2096477.758 \n",
      "Sample 496 \n",
      "Sample 497 \n",
      "Sample 498 \n",
      "Sample 499 \n",
      "Sample 500   Log joint likelihood = -2096575.921 \n",
      "Using all samples\n",
      "DONE. Time=1345.12675595\n"
     ]
    }
   ],
   "source": [
    "### all the parameters you need to specify to run LDA ###\n",
    "\n",
    "n_topics = 300 # 300 - 400 topics from cross-validation\n",
    "n_samples = 500 # 100 is probably okay for testing. For manuscript, use > 500-1000.\n",
    "n_burn = 250 # if 0 then we only use the last sample\n",
    "n_thin = 5 # every n-th sample to use for averaging after burn-in\n",
    "alpha = 50.0/n_topics # hyper-parameter for document-topic distributions\n",
    "beta = 0.1 # hyper-parameter for topic-word distributions\n",
    "\n",
    "ms2lda.run_lda(n_topics, n_samples, n_burn, n_thin, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing topics to results/beer3_test_method3/beer3_test_method3_topics.csv\n",
      "Writing fragments x topics to results/beer3_test_method3/beer3_test_method3_all.csv\n",
      "Writing topic docs to results/beer3_test_method3/beer3_test_method3_docs.csv\n",
      "Project saved to results/beer3pos.project time taken = 21.3921849728\n"
     ]
    }
   ],
   "source": [
    "ms2lda.write_results('beer3_test_method3')\n",
    "ms2lda.save_project('results/beer3pos.project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Resuming from Previous Run</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did the save_project() above, you can resume from this step directly the next time you load the notebook .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "basedir = '../'\n",
    "sys.path.append(basedir)\n",
    "\n",
    "from lda_for_fragments import Ms2Lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project loaded from results/beer3pos.project time taken = 16.8985421658\n",
      " - input_filenames = \n",
      "\t../input/final/Beer_3_full1_5_2E5_pos_fragments.csv\n",
      "\t../input/final/Beer_3_full1_5_2E5_pos_losses.csv\n",
      "\t../input/final/Beer_3_full1_5_2E5_pos_ms1.csv\n",
      "\t../input/final/Beer_3_full1_5_2E5_pos_ms2.csv\n",
      " - df.shape = (1588, 3171)\n",
      " - K = 300\n",
      " - alpha = 0.166666666667\n",
      " - beta = 0.1\n",
      " - last_saved_timestamp = Thu Aug  6 16:13:04 2015\n"
     ]
    }
   ],
   "source": [
    "ms2lda = Ms2Lda.resume_from('results/beer3pos.project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Visualisation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the 'interactive' parameter below is True, we will show an interactive visualisation of the results in a separate tab. You need to interrupt the kernel to stop it once you're done with it (from the menu above, Kernel > Interrupt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking topics ...\n"
     ]
    }
   ],
   "source": [
    "ms2lda.plot_lda_fragments(consistency=0.50, sort_by=\"h_index\", interactive=True)\n",
    "# ms2lda.plot_lda_fragments(consistency=0.50, sort_by=\"in_degree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
