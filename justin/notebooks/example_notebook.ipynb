{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Notebook\n",
    "============"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Run LDA the first time</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "basedir = '../'\n",
    "sys.path.append(basedir)\n",
    "\n",
    "from lda_for_fragments import Ms2Lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fragment_filename = basedir + 'input/final/Beer_3_full1_5_2E5_pos_fragments.csv'\n",
    "neutral_loss_filename = basedir + 'input/final/Beer_3_full1_5_2E5_pos_losses.csv'\n",
    "mzdiff_filename = None\n",
    "ms1_filename = basedir + 'input/final/Beer_3_full1_5_2E5_pos_ms1.csv'\n",
    "ms2_filename = basedir + 'input/final/Beer_3_full1_5_2E5_pos_ms2.csv'\n",
    "ms2lda = Ms2Lda.lcms_data_from_R(fragment_filename, neutral_loss_filename, mzdiff_filename, \n",
    "                             ms1_filename, ms2_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### all the parameters you need to specify to run LDA ###\n",
    "\n",
    "n_topics = 300 # 300 - 400 topics from cross-validation\n",
    "n_samples = 10 # 100 is probably okay for testing. For manuscript, use > 500-1000.\n",
    "n_burn = 0 # if 0 then we only use the last sample\n",
    "n_thin = 1 # every n-th sample to use for averaging after burn-in\n",
    "alpha = 50.0/n_topics # hyper-parameter for document-topic distributions\n",
    "beta = 0.1 # hyper-parameter for topic-word distributions\n",
    "\n",
    "ms2lda.run_lda(n_topics, n_samples, n_burn, n_thin, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ms2lda.save_project('results/beer3pos.project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Resuming from Previous Run</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did the save_project() above, you can resume from this step directly the next time you load the notebook .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "basedir = '../'\n",
    "sys.path.append(basedir)\n",
    "\n",
    "from lda_for_fragments import Ms2Lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ms2lda = Ms2Lda.resume_from('results/beer3pos.project')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Results</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to threshold the document-topic and topic-word distributions produced by LDA, so we can say which topics are used in which documents, and which words 'belongs' to a topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fixed thresholding of 0.05 for the doc_topic and topic_word matrices\n",
    "# NOTE: this is what we used before ..\n",
    "ms2lda.do_thresholding(th_doc_topic=0.05, th_topic_word=0.05)\n",
    "\n",
    "# Doc_topic matrix is thresholded at 0.05\n",
    "# Topic_word matrix is thresholded by the smallest value in each row\n",
    "# ms2lda.do_thresholding(th_doc_topic=0.05, th_topic_word=0.0)\n",
    "\n",
    "# Both matrices are thresholded by the smallest value in each row \n",
    "# Seems a bit difficult to visualise the results effectively due to the very high number of MS1 peaks per topic?\n",
    "# ms2lda.do_thresholding(th_doc_topic=0.0, th_topic_word=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the words in each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ms2lda.print_topic_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the output CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ms2lda.write_results('beer3_test_method3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set into the list below the MS1 peaks that you want to color differently in the graph page. You can see the names from the label of the nodes in the graph page or also from the CSV matrices written above. \n",
    "\n",
    "Also, for the graph page, you can which nodes are to be coloured differently. Add the node label to the list below and specify its colour, using either the colour name or its hex code (see http://www.w3schools.com/cssref/css_colornames.asp for the list of colour names/codes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a nice default maroon colour for highlighted nodes in the graph\n",
    "default_colour = '#CC0000'\n",
    "\n",
    "# specify each node and its respective colour here\n",
    "special_nodes = [\n",
    "    ('doc_372.18877_540.996', default_colour),\n",
    "    ('doc_291.66504_547_239', 'gold'),\n",
    "    ('doc_308.17029_289.13', '#C71585'),\n",
    "    ('topic_244', default_colour),\n",
    "    ('topic_98', 'aqua'),\n",
    "    ('topic_293', '#ff1493')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the 'interactive' parameter below is True, we will show an interactive visualisation of the results in a separate tab. You need to interrupt the kernel to stop it once you're done with it (from the menu above, Kernel > Interrupt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ms2lda.plot_lda_fragments(consistency=0.0, interactive=True, to_highlight=special_nodes)\n",
    "# ms2lda.plot_lda_fragments(consistency=0.50, sort_by=\"in_degree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
