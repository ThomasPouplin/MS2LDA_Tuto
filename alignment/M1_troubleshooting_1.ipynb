{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Checking the low recall when aligning M1 data with method #1</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from discretisation.preprocessing import FileLoader\n",
    "from models import HyperPars as AlignmentHyperPars\n",
    "from discretisation.adduct_cluster import AdductCluster, Peak\n",
    "from shared_bin_matching import SharedBinMatching as Aligner\n",
    "from ground_truth import GroundTruth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>0. Precursor Clustering on each file</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_dir = '/home/joewandy/git/metabolomics_tools/alignment/input/M1_4'\n",
    "database_file = None\n",
    "transformation_file = '/home/joewandy/git/metabolomics_tools/discretisation/mulsubs/pos_transformations.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hp = AlignmentHyperPars()    \n",
    "hp.within_file_mass_tol = 10\n",
    "hp.within_file_rt_tol = 5\n",
    "hp.across_file_mass_tol = 30\n",
    "hp.across_file_rt_tol = 100\n",
    "hp.alpha_mass = 1.0\n",
    "hp.dp_alpha = 100.0\n",
    "hp.t = 0\n",
    "hp.mass_clustering_n_iterations = 100\n",
    "hp.rt_clustering_nsamps = 200\n",
    "hp.rt_clustering_burnin = 100\n",
    "\n",
    "print hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loader = FileLoader()\n",
    "data_list = loader.load_model_input(input_dir, database_file, 0, 0, make_bins=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reasons, the cell below that does precursor clustering for each file takes **a lot** longer to run in the notebook vs. when run outside ... Not sure why??!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustering_results = []\n",
    "for peak_data in data_list:\n",
    "\n",
    "    ac = AdductCluster(mass_tol=hp.within_file_mass_tol, rt_tol=hp.within_file_rt_tol, \n",
    "                       alpha=hp.alpha_mass, mh_biggest=True, transformation_file=transformation_file, verbose=2)\n",
    "\n",
    "    peak_list = peak_data.features\n",
    "    ac.init_from_list(peak_list)\n",
    "\n",
    "    ac.init_vb()\n",
    "    for n in range(hp.mass_clustering_n_iterations):\n",
    "        print \"VB step %d file %d \" % (n, j)\n",
    "        sys.stdout.flush()\n",
    "        ac.vb_step()\n",
    "        \n",
    "    clustering_results.append(ac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Checking</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project loaded from /home/joewandy/git/metabolomics_tools/alignment/input/M1_4/results.project time taken = 19.7304940224\n"
     ]
    }
   ],
   "source": [
    "aligner = Aligner.resume_from('/home/joewandy/git/metabolomics_tools/alignment/input/M1_4/results.project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters across_file_mass_tol=30.0, across_file_rt_tol=100.0, alpha_mass=1.0, beta=0.1, dp_alpha=100.0, mass_clustering_n_iterations=100, rt_clustering_burnin=20, rt_clustering_nsamps=40, t=0.0, within_file_mass_tol=10.0, within_file_rt_tol=5.0\n"
     ]
    }
   ],
   "source": [
    "data_list = aligner.data_list\n",
    "hp = aligner.hp\n",
    "file_adduct_clusterers = aligner.clustering_results # list of adduct clusterer for each file\n",
    "file_clusterings = aligner.file_data # dict of file idx to the list of clusters in that file\n",
    "print hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find some big clusters in the first file. We have performed MAP assignment of each peak feature into its most likely cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_biggest(file_idx, threshold):\n",
    "\n",
    "    ac = file_adduct_clusterers[file_idx]\n",
    "    clusters_list = file_clusterings[file_idx]\n",
    "    singleton_count = 0\n",
    "    \n",
    "    big_clusters = []\n",
    "    biggest = clusters_list[0]\n",
    "    for cluster in clusters_list:\n",
    "        if cluster.N == 1:\n",
    "            singleton_count += 1\n",
    "        if cluster.N >= threshold:\n",
    "            big_clusters.append(cluster)\n",
    "            if cluster.N >= biggest.N:\n",
    "                biggest = cluster\n",
    "\n",
    "    print \"Singleton count {}\".format(singleton_count)\n",
    "    print \"{} big clusters found\".format(len(big_clusters))\n",
    "    print \"Biggest has {} members\".format(biggest.N)\n",
    "\n",
    "    for c in big_clusters:\n",
    "        ac.cluster_plot(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_biggest(file_idx=0, threshold=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_biggest(file_idx=1, threshold=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out all the aligned peaksets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aligned_peaksets = []\n",
    "i = 0\n",
    "for i in range(len(aligner.alignment_results)):\n",
    "    peakset = aligner.alignment_results[i].peakset\n",
    "    aligned_peaksets.append(peakset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the ground truth and check the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_list = aligner.file_list\n",
    "gt_file = '/home/joewandy/git/metabolomics_tools/alignment/input/M1_4/ground_truth/ground_truth.txt'\n",
    "gt = GroundTruth(gt_file, file_list, data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def found_in(gt_entry, aligned_peaksets):\n",
    "    for ps in aligned_peaksets:\n",
    "        ps_keys = [f._get_key() for f in ps]\n",
    "        for f in gt_entry:\n",
    "            if f._get_key() not in ps_keys:\n",
    "                all_found = False\n",
    "        if all_found:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "groups = gt.gt_features\n",
    "not_found_list = []\n",
    "found_list = []\n",
    "for group in groups:\n",
    "    found = found_in(group, aligned_peaksets)\n",
    "    if not found: # store the not-found ground truth entries\n",
    "        not_found_list.append(group)\n",
    "    else:\n",
    "        found_list.append(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Aligned peaksets that agree with ground truth = %d/%d\" % (len(found_list), len(groups)) \n",
    "print \"Aligned peaksets that disagree with ground truth = %d/%d\" % (len(not_found_list), len(groups)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the found ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for group in found_list:\n",
    "    print \"Group %d\" % i\n",
    "    i += 1\n",
    "    for f in group:\n",
    "        key = f._get_key()\n",
    "        annot = aligner.annotations[key]\n",
    "        print \"- id %s mass %.4f rt %.2f MAP_trans %s\" % ((key, f.mass, f.rt, annot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the not-found ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_overlap(gt_entry, aligned_peaksets):\n",
    "    overlap = []\n",
    "    for ps in aligned_peaksets:\n",
    "        ps_keys = [f._get_key() for f in ps]\n",
    "        any_found = False\n",
    "        for f in gt_entry:\n",
    "            if f._get_key() in ps_keys:\n",
    "                any_found = True\n",
    "        if any_found:\n",
    "            overlap.append(ps)\n",
    "    return overlap\n",
    "\n",
    "def print_peakset(peakset):\n",
    "    print \"\\tPeakset\"\n",
    "    for f in peakset:\n",
    "        key = f._get_key()\n",
    "        annot = aligner.annotations[key]\n",
    "        print \"\\t- id %s mass %.4f rt %.2f MAP_trans %s\" % ((key, f.mass, f.rt, annot))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for group in not_found_list:\n",
    "    \n",
    "    print \"Ground Truth Group %d\" % i\n",
    "    i += 1\n",
    "    for f in group:\n",
    "        key = f._get_key()\n",
    "        print \"- id %s mass %.4f rt %.2f\" % ((key, f.mass, f.rt))\n",
    "    \n",
    "    print \"Overlapping peaksets:\"\n",
    "    overlap = find_overlap(group, aligned_peaksets)\n",
    "    for ps in overlap:\n",
    "        print_peakset(ps)\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some peaks seem to have disappeared from the output aligned peaksets? This looks like a bug, which explains the lower recall ... For example, peak (1327, 1) below .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Found in input file?\"\n",
    "for f in data_list[1].features:\n",
    "    key = f._get_key()\n",
    "    if (1327, 1) == key:\n",
    "        print \"- id %s mass %.4f rt %.2f\" % ((key, f.mass, f.rt))\n",
    "\n",
    "# check in the output of first-stage clustering\n",
    "print \"\\nAnd also in the clustering\"\n",
    "first_file_clusterings = file_clusterings[1]\n",
    "for cluster in first_file_clusterings:\n",
    "    member_keys = [f._get_key() for f, poss in cluster.members]\n",
    "    if (1327, 1) in member_keys:\n",
    "        print \"Cluster %d %.4f %.2f\" % (cluster.id, cluster.mu_mass, cluster.mu_rt)\n",
    "        print member_keys   \n",
    "        for f, poss in cluster.members:\n",
    "            print \"- id %s mass %.4f rt %.2f\" % ((f._get_key(), f.mass, f.rt))\n",
    "\n",
    "# check in the output aligned peaksets\n",
    "print \"\\nBut missing in the output ??!!\"\n",
    "for ps in aligned_peaksets:\n",
    "    ps_keys = [f._get_key() for f in ps]\n",
    "    if (1327, 1) in ps_keys:\n",
    "        print ps_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
